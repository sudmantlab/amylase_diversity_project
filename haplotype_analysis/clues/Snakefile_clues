#!vim set syntax=python
import allel
import pdb
import numpy as np
import pandas as pd
from os.path import exists


configfile: "config.json"

rule all:
    input:
        "output/ancient_timecourse/AMY/combined_clues.tsv",
        "output/ancient_timecourse/AMY/positions.tsv"
        #"output/ancient_timecourse/AMY/clues_out_traj_plot/103575476.clues.tsv"


def get_GT_by_sample(callset):
    samples = callset['samples']
    GPs = callset['calldata/GP']
    GTs = callset['calldata/GT']
    poses = callset['variants/POS']
    AF = callset['variants/AF']

    for ix, pos in enumerate(poses):

        GP = GPs[ix,:,:]
        GT = GTs[ix,:,:]
        GL_by_sample = {}
        GT_by_sample = {}
        outrows = []
        #if AF[ix][0] < min_AF:
        #    continue
        for k, sample in enumerate(samples):
            #print(GP[k])
            #if np.isnan(GP[k][0]):
            #    print(sample)
            #    pdb.set_trace()
            #    continue
            GL_by_sample[sample] = np.log10(GP[k])
            GT_by_sample[sample] = GT[k]
        yield (pos, GL_by_sample, GT_by_sample)


def load_ancient_inf(fn):
    inf_by_sample = {}
    t = pd.read_csv(fn, header=0, sep="\t")
    for i,r in t.iterrows():
        age = r['ageAverage']
        if age=="UNKNOWN":
            continue
        else:
            age = float(age)
        inf_by_sample[r['sample']] = {"popGrouping":r['popGrouping'],
                                      "age":age}
    return inf_by_sample

def get_clues_input(wildcards):
    fn_checkpoint_output = checkpoints.get_pos.get(**wildcards).output[0]
    #fn_pos = "output/ancient_timecourse/{locus}/positions.tsv".format(locus=wildcards.locus)
    t = pd.read_csv(fn_checkpoint_output, header=0, sep="\t")
    inputs = []
    for p in t.position.values:
        pattern = "output/ancient_timecourse/{locus}/clues_out/{pos}.clues.tsv"
        inputs.append(pattern.format(locus=wildcards.locus,
                                     pos=p))
    return inputs 

rule combine_clues:
    input:
        get_clues_input
    output:
        "output/ancient_timecourse/{locus}/combined_clues.tsv"
    run:
        tables = []
        for fn in input:
            pos = fn.split("/")[-1].split(".")[0]
            fn_modern = "output/ancient_timecourse/{locus}/data/{pos}.modernf.txt"
            fn_modern = fn_modern.format(locus=wildcards.locus,pos=pos)
            modern_f = pd.read_csv(fn_modern,header=0,sep="\t")
            f = modern_f['modern'].values[0]
            t = pd.read_csv(fn,header=0,sep="\t")
            t['position'] = pos
            t['f'] = f
            tables.append(t)
        t = pd.concat(tables)
        t.to_csv(output[0], index=False, sep="\t")
        #pvalue=1-chi2.cdf(16.2079,df=1)

rule run_clues:
    input:
        fn_time="output/ancient_timecourse/{locus}/timeBins.txt",
        fn_samples="output/ancient_timecourse/{locus}/data/{pos}.AncientSamps.txt",
        fn_freq="output/ancient_timecourse/{locus}/data/{pos}.modernf.txt"
    output:
        clues_out="output/ancient_timecourse/{locus}/clues_out/{pos}.clues.tsv"
    run:
        modern_f = pd.read_csv(input.fn_freq,header=0,sep="\t")
        f = modern_f['modern'].values[0]
        cmd = ("python ~/Documents/science/programs/clues/inference.py "
               "--ancientSamps {fn_samps} "
               "--coal ./coal/1000G_phase3-FIN_GBR_TSI-popsize.coal "
               "--timeBins {fn_time} "
               "--popFreq {f} "
               ">{fn_out}"
               "".format(fn_time=input.fn_time,
                         fn_samps = input.fn_samples,
                         fn_out=output.clues_out,
                         f=f)) 
        shell(cmd)


rule run_clues_trajplot:
    input:
        fn_time="output/ancient_timecourse/{locus}/timeBins.txt",
        fn_samples="output/ancient_timecourse/{locus}/data/{pos}.AncientSamps.txt",
        fn_freq="output/ancient_timecourse/{locus}/data/{pos}.modernf.txt"
    output:
        clues_out="output/ancient_timecourse/{locus}/clues_out_traj_plot/{pos}.clues.tsv"
    run:
        modern_f = pd.read_csv(input.fn_freq,header=0,sep="\t")
        f = modern_f['modern'].values[0]
        cmd = ("python ~/Documents/science/programs/clues/inference.py "
               "--ancientSamps {fn_samps} "
               "--coal ./coal/1000G_phase3-FIN_GBR_TSI-popsize.coal "
               "--timeBins {fn_time} "
               "--popFreq {f} "
               "--out {out}"
               ">{fn_out}"
               "".format(fn_time=input.fn_time,
                         fn_samps = input.fn_samples,
                         fn_out=output.clues_out,
                         out=output.clues_out,
                         f=f)) 
        shell(cmd)
        cmd = ("python ~/Documents/science/programs/clues/plot_traj.py "
               "{path} "
               "{path}.fig".format(path=output.clues_out))
        shell(cmd)
        cmd = ("python ~/Documents/science/programs/clues/inference.py "
               "--ancientSamps {fn_samps} "
               "--coal ./coal/1000G_phase3-FIN_GBR_TSI-popsize.coal "
               "--timeBins {fn_time} "
               "--popFreq {f} "
               ">{fn_out}"
               "".format(fn_time=input.fn_time,
                         fn_samps = input.fn_samples,
                         fn_out=output.clues_out,
                         out=output.clues_out,
                         f=f)) 
        shell(cmd)

# python ~/Documents/science/programs/clues/plot_traj.py test test.fig
##
##

rule make_timebins:
    output:
        "output/ancient_timecourse/{locus}/timeBins.txt"
    run:
        kya = 15000
        gens = kya/config["generation_time"]
        str = "0.0\n{gens}".format(gens=gens)
        open(output[0],'w').write(str)

def get_modern_af(GTs, inf):
    n=0
    s=0
    for k,v in inf.items():
        n=n+2
        s=s+np.sum(GTs[k])
    return float(s)/n

checkpoint get_pos:
    output:
        "output/ancient_timecourse/{locus}/positions.tsv"
    run:
        min_af = 0.05
        outdir = "output/ancient_timecourse/{loc}/data".format(loc=wildcards.locus)
        shell("mkdir -p {outdir}".format(outdir=outdir))

        fn_vcf="input/1.neo.impute.1000g.vcf.gz"
        
        contig = config['loci'][wildcards.locus]["contig"]
        start = config['loci'][wildcards.locus]["start"]
        end = config['loci'][wildcards.locus]["end"]

        loc="{contig}:{s}-{e}".format(contig=contig,
                                      s=start,
                                      e=end)
        ancient_inf = load_ancient_inf("./metadata/ancient_info.tsv")
        #ancient_inf = load_ancient_inf("./metadata/ancient_info_exclude_AFR_AMR.tsv")
        modern_inf = load_ancient_inf("./metadata/modern_TSI_GBR_FIN.tsv")
        #modern_inf = load_ancient_inf("./metadata/modern_TSI_GBR.tsv")

        #ancient_inf = load_ancient_inf("./metadata/modern_and_ancient_european_TSI_GBR_FIN.tsv")

        callset = allel.read_vcf(fn_vcf,region=loc,fields="*")
        outpos = []
        for pos, GLs, GTs in get_GT_by_sample(callset):
            
            af = get_modern_af(GTs, modern_inf)
            if af<min_af:
                continue

            outpos.append({"position":pos})
            outrows = []

            for k,v in ancient_inf.items():
                if (not k in GLs) or (np.isnan(GLs[k][0])):
                    continue
                outrows.append({"sample":k,
                                "age":v['age']/config['generation_time'],
                                "0/0":GLs[k][0],
                                "1/0":GLs[k][1],
                                "1/1":GLs[k][2]})
                #pdb.set_trace()
            fn_out_modern = "{outdir}/{pos}.modernf.txt".format(outdir=outdir,pos=pos)
            open(fn_out_modern, 'w').write("modern\n{f}".format(f=af))
            fn_out = "{outdir}/{pos}.AncientSamps.txt".format(outdir=outdir,pos=pos)
            t = pd.DataFrame(outrows).sort_values(by="age",ascending=True)
            t.to_csv(fn_out,
                     columns=["age","0/0","1/0","1/1"],
                     sep=" ",
                     float_format="%e",
                     index=False,
                     header=False)
        
        t = pd.DataFrame(outpos)
        t.to_csv(output[0], sep="\t")

